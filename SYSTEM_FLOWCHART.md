# ğŸ”„ Complete System Flowchart

## What Happens When You Push to GitHub and Run

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                               â”‚
â”‚                    YOU PUSH TO GITHUB                                         â”‚
â”‚                    git push origin main                                       â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  GitHub Repository Updated          â”‚
        â”‚  â€¢ Code pushed to main branch        â”‚
        â”‚  â€¢ Commit: c25a60f visible          â”‚
        â”‚  â€¢ Ready for other developers       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  YOU START THE BACKEND              â”‚
        â”‚  $ python backend/main.py           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     BACKEND STARTUP SEQUENCE                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  1. Load Configuration (backend/config.py)                                  â•‘
â•‘     â”œâ”€ Load .env file (override=True)                                       â•‘
â•‘     â”œâ”€ Read Anthropic API Key                                               â•‘
â•‘     â”œâ”€ Read HuggingFace Token                                               â•‘
â•‘     â”œâ”€ Read Supabase credentials                                            â•‘
â•‘     â””â”€ AUTO-BUILD PostgreSQL connection string from Supabase               â•‘
â•‘        Example: postgresql+asyncpg://postgres:password@db.xxx.supabase.co  â•‘
â•‘                                                                              â•‘
â•‘  2. Initialize Audio Processing (backend/services/audio_processor.py)       â•‘
â•‘     â”œâ”€ Load Whisper model (speech-to-text)                                  â•‘
â•‘     â”œâ”€ Load Pyannote model (speaker diarization)                            â•‘
â•‘     â”œâ”€ Load Silero VAD (voice activity detection)                           â•‘
â•‘     â””â”€ Ready for audio processing requests                                  â•‘
â•‘                                                                              â•‘
â•‘  3. Initialize Storage Service (backend/services/storage.py)                â•‘
â•‘     â”œâ”€ Check for S3 credentials (optional)                                  â•‘
â•‘     â”œâ”€ If AWS credentials present: Use S3                                   â•‘
â•‘     â”œâ”€ Else: Use local filesystem (./uploads)                               â•‘
â•‘     â””â”€ Create storage directories if needed                                 â•‘
â•‘                                                                              â•‘
â•‘  4. Connect to Database (Supabase PostgreSQL)                               â•‘
â•‘     â”œâ”€ Create async connection pool (asyncpg)                               â•‘
â•‘     â”œâ”€ Auto-create tables on first run:                                     â•‘
â•‘     â”‚  â”œâ”€ conversations table (stores audio metadata)                       â•‘
â•‘     â”‚  â”œâ”€ participants table (identifies speakers)                          â•‘
â•‘     â”‚  â”œâ”€ transcripts table (stores text output)                            â•‘
â•‘     â”‚  â””â”€ entities & action_items tables                                    â•‘
â•‘     â””â”€ Verify connection to Supabase                                        â•‘
â•‘                                                                              â•‘
â•‘  5. Initialize FastAPI Server                                              â•‘
â•‘     â”œâ”€ Register API routes                                                  â•‘
â•‘     â”œâ”€ Configure CORS (localhost:5173, localhost:3000)                     â•‘
â•‘     â”œâ”€ Enable file uploads (multipart/form-data)                            â•‘
â•‘     â””â”€ Start Uvicorn server at http://0.0.0.0:8000                          â•‘
â•‘                                                                              â•‘
â•‘  âœ… Server Ready! Listening for requests...                                 â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                     â”‚
                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  SERVER RUNNING                     â”‚
        â”‚  http://localhost:8000              â”‚
        â”‚  Ready for audio uploads            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      USER UPLOADS AUDIO FILE                                 â”‚
â”‚                  POST /audio/process                                         â”‚
â”‚              with audio file (WAV, MP3, M4A, OGG, FLAC)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    AUDIO PROCESSING PIPELINE                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  STEP 1: Receive & Validate File                                            â•‘
â•‘  â”œâ”€ Check file size (< 100MB)                                               â•‘
â•‘  â”œâ”€ Check file format (MP3, WAV, M4A, OGG, FLAC)                            â•‘
â•‘  â””â”€ Generate unique conversation_id (e.g., "conv_abc123def456")            â•‘
â•‘                                                                              â•‘
â•‘  STEP 2: Store Original Audio File                                          â•‘
â•‘  â”œâ”€ Save to: ./uploads/conv_abc123def456.wav (or original format)           â•‘
â•‘  â”œâ”€ Generate metadata JSON                                                  â•‘
â•‘  â””â”€ Store location for future reference                                     â•‘
â•‘                                                                              â•‘
â•‘  STEP 3: Process Audio in Parallel (Async)                                  â•‘
â•‘  â”‚                                                                           â•‘
â•‘  â”œâ”€ Path A: TRANSCRIPTION (Whisper)                                         â•‘
â•‘  â”‚  â”œâ”€ Convert audio to 16kHz mono PCM                                      â•‘
â•‘  â”‚  â”œâ”€ Run through OpenAI Whisper model                                     â•‘
â•‘  â”‚  â”œâ”€ Output: Text with timestamps                                         â•‘
â•‘  â”‚  â””â”€ Example:                                                             â•‘
â•‘  â”‚     [0.0-5.2s] "Hello everyone, welcome to our meeting"                 â•‘
â•‘  â”‚     [5.2-10.1s] "Let's discuss the project plan"                        â•‘
â•‘  â”‚                                                                           â•‘
â•‘  â””â”€ Path B: SPEAKER DIARIZATION (Pyannote)                                  â•‘
â•‘     â”œâ”€ Extract voice embeddings from audio                                  â•‘
â•‘     â”œâ”€ Cluster similar voices (speaker identification)                      â•‘
â•‘     â”œâ”€ Output: Speaker turns with confidence scores                         â•‘
â•‘     â””â”€ Example:                                                             â•‘
â•‘        Speaker_0: [0.0-5.2s] confidence: 0.95                              â•‘
â•‘        Speaker_1: [5.2-10.1s] confidence: 0.92                             â•‘
â•‘                                                                              â•‘
â•‘  STEP 4: Match Speakers to Transcript (Greedy Algorithm)                    â•‘
â•‘  â”œâ”€ For each transcript segment:                                            â•‘
â•‘  â”‚  â”œâ”€ Find speaker turn with maximum time overlap                          â•‘
â•‘  â”‚  â””â”€ Calculate confidence = overlap_duration / segment_duration           â•‘
â•‘  â”‚                                                                           â•‘
â•‘  â””â”€ Result: Diarized transcript                                             â•‘
â•‘     Example:                                                                â•‘
â•‘     Speaker 1 [0.0-5.2s]: "Hello everyone, welcome to our meeting"         â•‘
â•‘     Speaker 2 [5.2-10.1s]: "Let's discuss the project plan"               â•‘
â•‘                                                                              â•‘
â•‘  STEP 5: Generate Output Transcript                                         â•‘
â•‘  â”œâ”€ Format human-readable transcript                                        â•‘
â•‘  â”œâ”€ Save to: ./uploads/conv_abc123def456_transcript.txt                    â•‘
â•‘  â””â”€ Content:                                                                â•‘
â•‘     [Speaker 1, 0:00-0:05] "Hello everyone, welcome to our meeting"       â•‘
â•‘     [Speaker 2, 0:05-0:10] "Let's discuss the project plan"               â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      â”‚
                      â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    STORE DATA (3 Places)                                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                              â•‘
â•‘  STORAGE LOCATION 1: Local Filesystem (./uploads)                           â•‘
â•‘  â”œâ”€ conv_abc123def456.wav                                                   â•‘
â•‘  â”‚  â””â”€ Original audio file                                                  â•‘
â•‘  â”œâ”€ conv_abc123def456_transcript.txt                                        â•‘
â•‘  â”‚  â””â”€ Human-readable diarized transcript                                   â•‘
â•‘  â””â”€ conv_abc123def456.json                                                  â•‘
â•‘     â””â”€ Metadata (speakers, confidence, duration, timestamps)                â•‘
â•‘                                                                              â•‘
â•‘  STORAGE LOCATION 2: Supabase PostgreSQL Database                           â•‘
â•‘  â”œâ”€ Table: conversations                                                    â•‘
â•‘  â”‚  â”œâ”€ id: "conv_abc123def456"                                              â•‘
â•‘  â”‚  â”œâ”€ title: (optional user title)                                         â•‘
â•‘  â”‚  â”œâ”€ audio_file_path: "./uploads/conv_abc123def456.wav"                  â•‘
â•‘  â”‚  â”œâ”€ transcript_file_path: "./uploads/conv_abc123def456_transcript.txt"  â•‘
â•‘  â”‚  â”œâ”€ speaker_count: 2                                                     â•‘
â•‘  â”‚  â”œâ”€ total_duration: 10.1                                                 â•‘
â•‘  â”‚  â”œâ”€ created_at: 2026-02-14T20:30:45.123Z                                 â•‘
â•‘  â”‚  â””â”€ updated_at: 2026-02-14T20:30:45.123Z                                 â•‘
â•‘  â”‚                                                                           â•‘
â•‘  â”œâ”€ Table: participants                                                     â•‘
â•‘  â”‚  â”œâ”€ id: 1                                                                â•‘
â•‘  â”‚  â”œâ”€ conversation_id: "conv_abc123def456"                                 â•‘
â•‘  â”‚  â”œâ”€ speaker_id: 0                                                        â•‘
â•‘  â”‚  â”œâ”€ name: (optional - "John", "Sarah", etc.)                            â•‘
â•‘  â”‚  â”œâ”€ confidence: 0.95                                                     â•‘
â•‘  â”‚  â””â”€ speaking_duration: 5.2 (seconds)                                     â•‘
â•‘  â”‚                                                                           â•‘
â•‘  â”œâ”€ Table: segments (transcript segments)                                   â•‘
â•‘  â”‚  â”œâ”€ id: 1                                                                â•‘
â•‘  â”‚  â”œâ”€ conversation_id: "conv_abc123def456"                                 â•‘
â•‘  â”‚  â”œâ”€ speaker_id: 0                                                        â•‘
â•‘  â”‚  â”œâ”€ start_time: 0.0                                                      â•‘
â•‘  â”‚  â”œâ”€ end_time: 5.2                                                        â•‘
â•‘  â”‚  â”œâ”€ text: "Hello everyone, welcome to our meeting"                      â•‘
â•‘  â”‚  â””â”€ confidence: 0.95                                                     â•‘
â•‘  â”‚                                                                           â•‘
â•‘  â””â”€ Tables: entities, action_items                                          â•‘
â•‘     â””â”€ (Created for future extraction of key information)                   â•‘
â•‘                                                                              â•‘
â•‘  STORAGE LOCATION 3 (Optional): AWS S3                                      â•‘
â•‘  â”œâ”€ If AWS credentials set in .env:                                         â•‘
â•‘  â”‚  â”œâ”€ Bucket: aperta-audio                                                 â•‘
â•‘  â”‚  â”œâ”€ Path: conv_abc123def456/audio.wav                                    â•‘
â•‘  â”‚  â”œâ”€ Path: conv_abc123def456/transcript.txt                               â•‘
â•‘  â”‚  â””â”€ Path: conv_abc123def456/metadata.json                                â•‘
â•‘  â””â”€ Else: Uses local filesystem (fallback)                                  â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RETURN API RESPONSE                                       â”‚
â”‚                                                                              â”‚
â”‚  HTTP 200 OK                                                                â”‚
â”‚  {                                                                          â”‚
â”‚    "conversation_id": "conv_abc123def456",                                 â”‚
â”‚    "audio_file_path": "./uploads/conv_abc123def456.wav",                  â”‚
â”‚    "transcript_file_path": "./uploads/conv_abc123def456_transcript.txt",  â”‚
â”‚    "transcript": "Speaker 1 [0:00-0:05] Hello everyone...",              â”‚
â”‚    "speaker_stats": {                                                      â”‚
â”‚      "Speaker 1": {"duration": 5.2, "segments": 1, "confidence": 0.95},  â”‚
â”‚      "Speaker 2": {"duration": 4.9, "segments": 1, "confidence": 0.92}   â”‚
â”‚    },                                                                      â”‚
â”‚    "total_duration": 10.1,                                                â”‚
â”‚    "speaker_count": 2,                                                    â”‚
â”‚    "created_at": "2026-02-14T20:30:45.123Z"                              â”‚
â”‚  }                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND RECEIVES DATA                                    â”‚
â”‚                                                                              â”‚
â”‚  1. Show transcript with speaker labels                                    â”‚
â”‚     [Speaker 1] "Hello everyone, welcome to our meeting"                  â”‚
â”‚     [Speaker 2] "Let's discuss the project plan"                          â”‚
â”‚                                                                              â”‚
â”‚  2. Display speaker statistics                                              â”‚
â”‚     Speaker 1: 5.2 seconds (52%)                                           â”‚
â”‚     Speaker 2: 4.9 seconds (48%)                                           â”‚
â”‚                                                                              â”‚
â”‚  3. Let user manage speakers (assign names, edit, etc.)                    â”‚
â”‚     Speaker 1 â†’ "John Smith"                                              â”‚
â”‚     Speaker 2 â†’ "Sarah Johnson"                                            â”‚
â”‚                                                                              â”‚
â”‚  4. Download transcript as text file (optional)                             â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow Summary

### Where Data Goes

```
User uploads WAV file
        â”‚
        â”œâ”€â”€â†’ Saved to: ./uploads/conv_abc123.wav
        â”‚
        â”œâ”€â”€â†’ Processed by Whisper (transcription)
        â”‚    â””â”€â”€â†’ Output: Text with timestamps
        â”‚
        â”œâ”€â”€â†’ Processed by Pyannote (diarization)
        â”‚    â””â”€â”€â†’ Output: Speaker turns
        â”‚
        â”œâ”€â”€â†’ Saved to: ./uploads/conv_abc123_transcript.txt
        â”‚
        â”œâ”€â”€â†’ Saved to: ./uploads/conv_abc123.json (metadata)
        â”‚
        â”œâ”€â”€â†’ Stored in Supabase PostgreSQL
        â”‚    â”œâ”€ conversations table
        â”‚    â”œâ”€ participants table
        â”‚    â”œâ”€ segments table
        â”‚    â””â”€ entities, action_items tables
        â”‚
        â”œâ”€â”€â†’ (Optional) Saved to AWS S3
        â”‚
        â””â”€â”€â†’ Returned to Frontend via API Response
             â””â”€â”€â†’ Display to User
```

---

## Database Schema (What's Stored in Supabase)

```sql
-- conversations table
CREATE TABLE conversations (
  id VARCHAR PRIMARY KEY,           -- "conv_abc123def456"
  title VARCHAR,                    -- optional user title
  audio_file_path VARCHAR,          -- "./uploads/conv_abc123def456.wav"
  transcript_file_path VARCHAR,     -- "./uploads/conv_abc123def456_transcript.txt"
  speaker_count INT,                -- 2
  total_duration FLOAT,             -- 10.1 seconds
  created_at TIMESTAMP,             -- when uploaded
  updated_at TIMESTAMP              -- last modified
);

-- participants (speakers) table
CREATE TABLE participants (
  id SERIAL PRIMARY KEY,
  conversation_id VARCHAR,          -- "conv_abc123def456"
  speaker_id INT,                   -- 0, 1, 2, etc.
  name VARCHAR,                     -- optional: "John", "Sarah"
  confidence FLOAT,                 -- 0.95
  speaking_duration FLOAT           -- 5.2 seconds
);

-- segments (transcript) table
CREATE TABLE segments (
  id SERIAL PRIMARY KEY,
  conversation_id VARCHAR,          -- "conv_abc123def456"
  speaker_id INT,                   -- 0, 1, etc.
  start_time FLOAT,                 -- 0.0
  end_time FLOAT,                   -- 5.2
  text VARCHAR,                     -- "Hello everyone..."
  confidence FLOAT                  -- 0.95
);

-- entities table (for future use)
CREATE TABLE entities (
  id SERIAL PRIMARY KEY,
  conversation_id VARCHAR,
  entity_text VARCHAR,              -- "John Smith"
  entity_type VARCHAR,              -- "PERSON", "COMPANY", etc.
  mentioned_by_speaker INT
);

-- action_items table (for future use)
CREATE TABLE action_items (
  id SERIAL PRIMARY KEY,
  conversation_id VARCHAR,
  item_text VARCHAR,                -- "Follow up with customer"
  assigned_to INT,                  -- speaker_id
  status VARCHAR                    -- "PENDING", "COMPLETED"
);
```

---

## File Storage Layout

```
./uploads/
â”œâ”€â”€ conv_abc123def456.wav
â”‚   â””â”€ Original audio file (can be large - 10MB+)
â”‚
â”œâ”€â”€ conv_abc123def456_transcript.txt
â”‚   â””â”€ Human-readable transcript
â”‚      [Speaker 1, 0:00-0:05] "Hello everyone..."
â”‚      [Speaker 2, 0:05-0:10] "Let's discuss..."
â”‚
â”œâ”€â”€ conv_abc123def456.json
â”‚   â””â”€ Metadata file
â”‚      {
â”‚        "conversation_id": "conv_abc123def456",
â”‚        "speaker_count": 2,
â”‚        "total_duration": 10.1,
â”‚        "speakers": [
â”‚          {"id": 0, "confidence": 0.95, "duration": 5.2},
â”‚          {"id": 1, "confidence": 0.92, "duration": 4.9}
â”‚        ],
â”‚        "segments": [...]
â”‚      }
â”‚
â”œâ”€â”€ conv_def789...
â”œâ”€â”€ conv_ghi123...
â””â”€â”€ ... (one directory per uploaded audio file)
```

---

## Complete Request/Response Example

### Request
```bash
curl -X POST http://localhost:8000/audio/process \
  -F "file=@meeting.wav"
```

### Response
```json
{
  "conversation_id": "conv_a1b2c3d4e5f6",
  "audio_file_path": "./uploads/conv_a1b2c3d4e5f6.wav",
  "transcript_file_path": "./uploads/conv_a1b2c3d4e5f6_transcript.txt",
  "transcript": "Speaker 1 [0:00-0:05] Hello everyone, welcome to our meeting\nSpeaker 2 [0:05-0:10] Let's discuss the project plan",
  "speaker_stats": {
    "Speaker 1": {
      "duration": 5.2,
      "segments": 1,
      "confidence": 0.95
    },
    "Speaker 2": {
      "duration": 4.9,
      "segments": 1,
      "confidence": 0.92
    }
  },
  "total_duration": 10.1,
  "speaker_count": 2,
  "created_at": "2026-02-14T20:30:45.123000+00:00"
}
```

---

## What Gets Stored - Summary Table

| What | Where | Why | Size |
|------|-------|-----|------|
| Original Audio File | `./uploads/*.wav` | Reference, future re-processing | 5-100MB+ |
| Transcript Text | `./uploads/*_transcript.txt` | User reads, downloads, shares | 10-100KB |
| Metadata JSON | `./uploads/*.json` | Timestamps, confidence scores | 5-50KB |
| Conversation Info | Supabase `conversations` | Database queries, organize | 1KB |
| Speaker Info | Supabase `participants` | Who spoke, confidence | 1KB per speaker |
| Transcript Segments | Supabase `segments` | Search, analyze, extract entities | 10-100KB |
| Entities (Future) | Supabase `entities` | Name extraction, PII detection | Variable |
| Action Items (Future) | Supabase `action_items` | Task tracking | Variable |
| Optional: S3 Backup | AWS S3 | Cloud backup, redundancy | Same as local |

---

## Timeline Example

```
User uploads 10-minute meeting recording

Time 0s:    Upload received
Time 1s:    Audio file saved to ./uploads/
Time 2-45s: Whisper transcription (GPU: ~5s, CPU: ~30s)
Time 45-90s: Pyannote speaker diarization (GPU: ~10s, CPU: ~40s)
Time 90s:   Matching speakers to transcript (instant)
Time 91s:   Save to database (Supabase)
Time 92s:   Return response to frontend
            â†’ User sees transcript with speaker labels immediately

TOTAL: ~90 seconds end-to-end (faster with GPU)
```

---

## Security & Privacy

```
What happens to your data:

âœ… Audio File
   â€¢ Stored locally in ./uploads/ (or S3 if configured)
   â€¢ NOT sent to external AI services
   â€¢ Stays under your control

âœ… Transcription
   â€¢ Done locally using Whisper model
   â€¢ Model downloaded once, runs locally
   â€¢ Text never sent externally

âœ… Speaker Diarization
   â€¢ Done locally using Pyannote model
   â€¢ Voice embeddings generated locally
   â€¢ Never leaves your server

âœ… Database
   â€¢ Supabase PostgreSQL in your account
   â€¢ You control access and retention
   â€¢ Can delete anytime

âœ… API Keys
   â€¢ Stored in .env (not in code)
   â€¢ Protected by .gitignore
   â€¢ Not committed to GitHub
```

This is everything that happens in your system! ğŸ‰
